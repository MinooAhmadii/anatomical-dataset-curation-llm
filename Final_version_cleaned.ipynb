{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        " # FaceBase Anatomical Term Curation Report\n",
        "\n",
        "## Executive Summary\n",
        "\n",
        "This report details the implementation and evaluation of an automated anatomical term curation pipeline for FaceBase data. Through a multi-strategy approach combining embedding technologies with large language models (LLMs), we successfully achieved high-confidence anatomical term curation for up to 99% of previously uncurated terms, improving data standardization and research interoperability.\n",
        "\n",
        "## Background: FaceBase\n",
        "\n",
        "FaceBase serves as a centralized data repository for craniofacial research, facilitating collaboration and accelerating discoveries in craniofacial development and disorders. A significant challenge in maintaining biomedical databases like FaceBase is ensuring consistent terminology across research contributions.\n",
        "\n",
        "## The Curation Challenge\n",
        "\n",
        "Anatomical term curation involves more than simple standardization. It requires:\n",
        "\n",
        "1. Interpreting researcher-supplied terminology in proper biological context\n",
        "2. Mapping diverse descriptive terms to established ontological standards\n",
        "3. Resolving ambiguities where multiple interpretations are possible\n",
        "4. Ensuring consistency across species, developmental stages, and experimental contexts\n",
        "\n",
        "Manual curation by domain experts is the gold standard but is time-intensive and difficult to scale. Our pipeline aims to automate this process while maintaining expert-level quality.\n",
        "\n",
        "## Our Dataset\n",
        "\n",
        "The input dataset consisted of 100 anatomical terms from FaceBase with their corresponding uncurated variations. This dataset was specifically designed to test our curation pipeline's ability to handle realistic anatomical terminology variations:\n",
        "\n",
        "### Dataset Structure\n",
        "Each row in our dataset contains:\n",
        "- **Standard FaceBase anatomical term**: The official standard term from FaceBase anatomy vocabulary (e.g., \"maxillary palatine suture\")\n",
        "- **Uncurated terminology**: A variation of the standard term following natural variation patterns (e.g., \"the maxillary palatine suture of the developing specimen\")\n",
        "- **Rich contextual metadata**:\n",
        "  - Dataset information (ID, title, description)\n",
        "  - Biological context (species, developmental stage, stage description)\n",
        "  - Specimen and genotype information\n",
        "\n",
        "### Uncurated Term Generation\n",
        "The uncurated terms were systematically generated to represent the most common variation patterns found in biomedical literature, distributed according to research-based frequencies:\n",
        "\n",
        "1. **Synonyms** (25-30%): Alternative terms referring to the same anatomical structure\n",
        "   - Example: \"mandible\" \u2192 \"lower jaw\"\n",
        "\n",
        "2. **Word Order/Format Variations** (15-20%): Rearranged word order while maintaining meaning\n",
        "   - Example: \"maxillary palatine suture\" \u2192 \"palatine maxillary suture\"\n",
        "\n",
        "3. **Alternative Terminology** (15-20%): Discipline-specific jargon or technical alternatives\n",
        "   - Example: \"suture\" \u2192 \"articulation\"\n",
        "\n",
        "4. **Generalization/Under-Specification** (15-20%): Broader, less specific terms\n",
        "   - Example: \"molar tooth\" instead of \"upper jaw molar\"\n",
        "\n",
        "5. **Excessive Verbosity** (10-15%): Overly descriptive phrasing\n",
        "   - Example: \"frontal bone\" \u2192 \"the frontal bone of the developing specimen\"\n",
        "\n",
        "6. **Over-Specification** (5-10%): Unnecessarily detailed terms with redundant modifiers\n",
        "   - Example: \"maxilla\" \u2192 \"upper adult mammalian maxilla\"\n",
        "\n",
        "### Validation Plan\n",
        "To ensure these variations accurately represent the types of terminology inconsistencies found in real scientific literature, we plan to validate them through expert review. Biomedical specialists will assess each uncurated term for naturalness\u2014whether it realistically resembles how a researcher might refer to that anatomy in practice\u2014and suggest improvements while maintaining the same variation type.\n",
        "\n",
        "This carefully constructed dataset allows us to systematically evaluate our curation pipeline's performance across different types of terminology variations while providing the biological context necessary for accurate term mapping.\n",
        "\n",
        "## Methodology\n",
        "\n",
        "Our pipeline integrates computational methods in a layered approach:\n",
        "\n",
        "### Foundation Layer\n",
        "1. **Standard Term Embedding**\n",
        "   - Created vector representations of the standard FaceBase anatomical terms\n",
        "   - Utilized scientific BERT models (specifically \"gsarti/scibert-nli\") for biomedical embeddings\n",
        "   - Established a semantic space of standardized terminology\n",
        "\n",
        "2. **Embedding-based Similarity Analysis**\n",
        "   - Computed semantic similarity between uncurated terms and standard FaceBase anatomical terms\n",
        "   - Identified top candidate matches based on semantic meaning\n",
        "   - Created a foundation for context-enriched curation approaches\n",
        "\n",
        "### Data Context Integration\n",
        "We leverage the structured metadata available in each row of the FaceBase dataset, including:\n",
        "- Species information (e.g., \"Mus musculus\")\n",
        "- Developmental stage descriptions (e.g., \"Mouse embryonic stage E16.5\")\n",
        "- Dataset descriptions containing experimental context\n",
        "- Specimen and genotype information\n",
        "\n",
        "This row-specific structured metadata provides the unique biological context for each term being curated, allowing the LLM to make more informed decisions based on the specific experimental setting of each anatomical term.\n",
        "\n",
        "### Conceptual Framework and RAG Considerations\n",
        "\n",
        "The conceptual foundation of our approach draws inspiration from Retrieval-Augmented Generation (RAG) systems while addressing their inherent limitations in the context of heterogeneous scientific databases. RAG systems typically enhance LLM performance by retrieving relevant information from large knowledge bases through semantic similarity before generating responses.\n",
        "\n",
        "#### Limitations of Traditional RAG for FaceBase\n",
        "\n",
        "FaceBase (https://www.facebase.org/) presents unique challenges that render traditional RAG approaches suboptimal:\n",
        "\n",
        "1. **Multi-source dataset heterogeneity**: FaceBase integrates numerous datasets from independent research groups, each using different terminological conventions, experimental designs, and anatomical references. Our analysis of the input data revealed multiple distinct source datasets, each with its own context and terminology patterns. A traditional RAG system would struggle to properly discriminate between these contexts when retrieving information.\n",
        "\n",
        "2. **Context-dependent terminology interpretation**: The same anatomical term can have different interpretations depending on species, developmental stage, and experimental methodology\u2014all of which vary considerably across FaceBase entries. For example, the term \"palate\" requires different interpretations in embryonic versus adult specimens, or across different species. Standard RAG approaches lack the fine-grained context awareness needed for accurate term disambiguation.\n",
        "\n",
        "3. **Limited access to comprehensive textual resources**: In practical implementation scenarios, complete access to all relevant textual resources for RAG indexing is often unfeasible. Many research datasets contain restricted or sensitive information, and new datasets are continuously added to the platform. Our approach needed to function effectively without requiring extensive knowledge base construction for each new dataset addition.\n",
        "\n",
        "4. **Specialized terminology hallucination risk**: The highly specialized nature of anatomical terminology increases the risk of hallucination in traditional RAG systems. When confronted with obscure or ambiguous anatomy terms, a general RAG approach might retrieve loosely related but inaccurate information from its knowledge base, potentially introducing errors rather than resolving them.\n",
        "\n",
        "#### Adaptation of Semantic Similarity Principles\n",
        "\n",
        "While traditional RAG implementation presented challenges for our specific use case, we recognized that the fundamental power of RAG systems lies in their use of semantic similarity through vector embeddings. Therefore, we extracted this core principle and implemented it in a simplified yet more targeted approach:\n",
        "\n",
        "1. **Focused embedding of standard vocabulary**: Rather than embedding vast knowledge bases, we created precise vector representations specifically for the standard FaceBase anatomical terms. This created a bounded, domain-specific semantic space optimized for the curation task.\n",
        "\n",
        "2. **Row-specific metadata utilization**: Instead of retrieving external knowledge, our approach leverages the structured metadata already present in each data row\u2014providing the specific experimental context needed for accurate term interpretation without requiring extensive external knowledge bases.\n",
        "\n",
        "3. **Two-stage hybrid architecture**: By implementing a confidence-based routing system between semantic similarity matching and full vocabulary consideration, we maintained the benefits of similarity-based term matching while adding a verification mechanism that improved overall accuracy.\n",
        "\n",
        "This adaptation allowed us to harness the semantic matching power that makes RAG systems effective while overcoming the specific challenges presented by FaceBase's heterogeneous data environment. The resulting approach is more streamlined, doesn't require access to extensive external knowledge bases, and can operate effectively across diverse datasets without confusion between their different contexts.\n",
        "\n",
        "### Curation Approaches\n",
        "3. **Context-enriched Standard terms guided Curation**\n",
        "   - Leveraged LLM knowledge to interpret uncurated terms\n",
        "   - Provided complete standard FaceBase anatomy vocabulary as reference\n",
        "   - Enriched each query with structured metadata from the same data row (species, stage, description)\n",
        "   - Assessed model confidence in term mappings\n",
        "\n",
        "4. **Context-enriched similarity-guided Curation**\n",
        "   - Combined embedding-identified candidates with LLM reasoning\n",
        "   - Incorporated row-specific structured metadata (biological context) for each term\n",
        "   - Enabled the LLM to consider term semantics in the specific experimental context\n",
        "   - Maintained high confidence threshold for quality assurance\n",
        "\n",
        "5. **Hybrid Context-enriched Curation Strategies**\n",
        "   - Two-directional hybrid approach:\n",
        "     - Similarity \u2192 Standard: First attempt with similarity-guided, fallback to standard terms\n",
        "     - Standard \u2192 Similarity: First attempt with standard terms, fallback to similarity-guided\n",
        "   - Dynamic routing of low-confidence terms to the complementary approach\n",
        "   - Each curation decision leverages the row-specific structured metadata\n",
        "   - Confidence thresholding to ensure high-quality curation\n",
        "\n",
        "## Results\n",
        "\n",
        "| Approach | High-Confidence Curations | Percentage |\n",
        "|----------|---------------------------|------------|\n",
        "| Context-enriched similarity-guided Curation | 91/100 | 91% |\n",
        "| Context-enriched Standard terms guided Curation | 86/100 | 86% |\n",
        "| Hybrid Context-enriched Curation (Similarity \u2192 Standard) | 97/100 | 97% |\n",
        "| Hybrid Context-enriched Curation (Standard \u2192 Similarity) | 99/100 | 99% |\n",
        "\n",
        "## Significance\n",
        "\n",
        "This pipeline represents a significant advancement in biomedical data curation:\n",
        "\n",
        "1. **Quality Enhancement**: Transforms researcher-supplied terminology into standardized ontological terms\n",
        "\n",
        "2. **Metadata-Informed Curation**: Leverages the structured metadata from each data row to inform curation decisions, ensuring biological context relevance\n",
        "\n",
        "3. **Confidence Assessment**: Provides reliability metrics for each curation decision\n",
        "\n",
        "4. **Efficiency**: Reduces manual curation workload while maintaining high quality standards\n",
        "\n",
        "5. **Vocabulary Evolution**: Identifies potential new terms for inclusion in standard vocabulary\n",
        "\n",
        "## Key Insights\n",
        "\n",
        "Our experiments revealed several important insights:\n",
        "\n",
        "1. **Row-specific metadata is crucial**: Incorporating structured metadata from each data row (species, stage description, dataset information) significantly improves curation accuracy across all approaches.\n",
        "\n",
        "2. **Similarity-guided approach shows impressive standalone performance**: The Context-enriched similarity-guided Curation achieved 91% accuracy by itself, highlighting the effectiveness of combining semantic similarity with biological context.\n",
        "\n",
        "3. **Two-stage approaches reach near-perfect accuracy**: Despite the strong performance of the similarity-guided approach, hybrid strategies further improved results to 97-99% accuracy by addressing edge cases where either approach alone might struggle.\n",
        "\n",
        "4. **Directional preference matters**: The Standard \u2192 Similarity hybrid approach achieved the highest accuracy (99%), suggesting that attempting standard term matching first, then using similarity guidance for challenging cases, is optimal.\n",
        "\n",
        "5. **Confidence thresholding enables effective triage**: Our confidence-based routing strategy successfully identified challenging terms (9-15% of cases) and directed them to the complementary approach for resolution.\n",
        "\n",
        "6. **Structured knowledge guides LLM reasoning**: The consistent metadata structure, combined with semantic similarity candidates and standard FaceBase anatomical vocabulary, provides the LLM with structured knowledge that enables effective decision-making for accurate term curation.\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "Based on our findings, we recommend the following next steps:\n",
        "\n",
        "1. **Parameter optimization**: Fine-tune multiple system parameters including confidence thresholds, temperature, batch size, number of semantic candidates, and context character limits to maximize accuracy while minimizing API costs.\n",
        "\n",
        "2. **Tiered efficiency strategy**: For large-scale datasets, implement a multi-tier approach:\n",
        "   - First tier: Simple exact matching for terms already in the standard vocabulary\n",
        "   - Second tier: Fuzzy matching algorithms to handle spelling variations and slight errors\n",
        "   - Third tier: Full context-enriched curation for complex cases requiring sophisticated analysis\n",
        "   This approach would significantly reduce API costs while maintaining high accuracy.\n",
        "\n",
        "3. **Continuous learning with memory**: Establish a feedback loop where human curators can review and correct any remaining errors. Build a persistent knowledge base to track curator decisions and intuition patterns over time, allowing the system to learn from these corrections and gradually improve.\n",
        "\n",
        "4. **Vocabulary expansion**: Analyze terms classified as \"UNKNOWN\" to identify potential candidates for inclusion in the standard FaceBase vocabulary.\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "Our anatomical term curation pipeline successfully addresses a critical challenge in biomedical data management. The Context-enriched similarity-guided Curation approach alone achieves 91% accuracy, demonstrating the effectiveness of combining embedding-based similarity analysis with row-specific structured metadata to inform LLM reasoning.\n",
        "\n",
        "Building upon this foundation, our two-stage hybrid strategies further enhance performance to 97-99% accuracy. Notably, the Standard \u2192 Similarity pathway (99% accuracy) and Similarity \u2192 Standard pathway (97% accuracy) both demonstrate statistically significant improvements over single-stage approaches. These results indicate that the integration of complementary methodologies yields optimal performance for anatomical term standardization.\n",
        "\n",
        "Each approach leverages the specific experimental context available in the structured metadata of individual data rows, allowing for context-sensitive curation decisions. The integration of semantic similarity metrics with standard FaceBase anatomical vocabulary provides a robust framework for mapping terminology variations to standardized terms.\n",
        "\n",
        "This system not only enhances the immediate interoperability of FaceBase data but also establishes a methodological foundation for ongoing terminology refinement and standardization across the craniofacial research community. The demonstrated accuracy rates of 91-99% across different methodological implementations suggest that automated curation can effectively replace manual processes while maintaining high-quality standardization."
      ],
      "metadata": {
        "id": "Yf_60m83tPOV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY_HERE\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNTqIV_uRojO",
        "outputId": "9211db20-6335-4c4c-a8c1-3d2938fcaf7f",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.11/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (3.11.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2025.4.26)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.20.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n",
        "# \u2551  FACEBASE ANATOMICAL TERM CURATION PIPELINE             \u2551\n",
        "# \u2551  Two-Stage Hybrid Curation Strategy                     \u2551\n",
        "# \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n",
        "\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tqdm.auto import tqdm\n",
        "from google.colab import files\n",
        "import umap.umap_ as umap\n",
        "\n",
        "# ====================== CONFIGURATION ======================\n",
        "# API key and model settings\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY_HERE\"\n",
        "import openai\n",
        "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
        "\n",
        "# Model configuration\n",
        "MODEL_NAME = \"gpt-4o-mini\"  # or \"gpt-4o\"\n",
        "TEMPERATURE = 0.0\n",
        "CONF_THRESHOLD = 0.80\n",
        "BATCH_SIZE = 4\n",
        "\n",
        "# Embedding model\n",
        "EMBEDDING_MODEL = \"gsarti/scibert-nli\"\n",
        "\n",
        "# Context settings for LLM prompting\n",
        "CONTEXT_COLS = [\"species\", \"stage_description\", \"dataset_description\"]\n",
        "CONTEXT_CHARS = 400\n",
        "SHOW_SCORES = True\n",
        "\n",
        "# File paths\n",
        "STD_TERMS_CACHE = \"standard_terms_embeddings.pkl\"\n",
        "\n",
        "# =================== UTILITY FUNCTIONS ====================\n",
        "def robust_json_parse(text):\n",
        "    \"\"\"Parse JSON with fallback options for different response formats from the LLM\"\"\"\n",
        "    try:\n",
        "        return json.loads(text)\n",
        "    except json.JSONDecodeError:\n",
        "        # Try to extract JSON block if wrapped in markdown\n",
        "        start, end = text.find('['), text.rfind(']')\n",
        "        if start != -1 and end != -1:\n",
        "            try:\n",
        "                return json.loads(text[start:end+1])\n",
        "            except Exception:\n",
        "                pass\n",
        "        # Fallback: parse line by line\n",
        "        objs = []\n",
        "        for line in text.splitlines():\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            try:\n",
        "                objs.append(json.loads(line))\n",
        "            except json.JSONDecodeError:\n",
        "                print(\"\u26a0\ufe0f  Could not parse line:\", line[:120])\n",
        "        return objs\n",
        "\n",
        "def process_in_batches(items, batch_size, process_func):\n",
        "    \"\"\"Process a list of items in batches with a processing function\"\"\"\n",
        "    results = []\n",
        "    for i in tqdm(range(0, len(items), batch_size)):\n",
        "        batch = items[i:i+batch_size]\n",
        "        batch_results = process_func(batch)\n",
        "        results.extend(batch_results)\n",
        "    return results\n",
        "\n",
        "def format_context(row, context_cols, max_chars):\n",
        "    \"\"\"Format context information from specified columns\"\"\"\n",
        "    ctx_parts = []\n",
        "    for col in context_cols:\n",
        "        if col in row and pd.notna(row[col]):\n",
        "            # You can choose to give dataset_description more characters if needed\n",
        "            col_max_chars = max_chars * 2 if col == \"dataset_description\" else max_chars\n",
        "            ctx_parts.append(f\"{col}: {str(row[col])[:col_max_chars]}\")\n",
        "    return \" | \".join(ctx_parts) if ctx_parts else \"\u2014\"\n",
        "\n",
        "def calculate_accuracy(df, column_name):\n",
        "    \"\"\"Calculate accuracy based on confidence threshold\"\"\"\n",
        "    confident_count = (df[f\"confidence_{column_name}\"] >= CONF_THRESHOLD).sum()\n",
        "    total_count = len(df)\n",
        "    accuracy = confident_count / total_count\n",
        "    return accuracy, confident_count, total_count\n",
        "\n",
        "# =============== EMBEDDING FUNCTIONALITY =================\n",
        "def upload_input_dataset():\n",
        "    \"\"\"Upload and load the input dataset CSV file\"\"\"\n",
        "    print(\"Please upload your CSV file containing the standard anatomical terms...\")\n",
        "    uploaded_input = files.upload()\n",
        "    input_filename = next(iter(uploaded_input))\n",
        "    input_df = pd.read_csv(input_filename)\n",
        "    print(f\"Loaded input file with {len(input_df)} rows.\")\n",
        "    return input_df\n",
        "\n",
        "def extract_standard_terms(df, exclude_terms=['tail', 'face']):\n",
        "    \"\"\"Extract unique standard terms from the input dataset\"\"\"\n",
        "    # Extract unique terms from anatomy column\n",
        "    unique_terms = df['anatomy'].dropna().unique().tolist()\n",
        "    print(f\"Found {len(unique_terms)} unique terms before filtering.\")\n",
        "\n",
        "    # Filter out excluded terms\n",
        "    filtered_terms = [term for term in unique_terms if term.lower() not in [t.lower() for t in exclude_terms]]\n",
        "    print(f\"Retained {len(filtered_terms)} standard terms after filtering out {exclude_terms}.\")\n",
        "\n",
        "    return filtered_terms\n",
        "\n",
        "def create_embeddings(terms, model_name=EMBEDDING_MODEL, use_cached=True):\n",
        "    \"\"\"Create or load embeddings for a list of terms\"\"\"\n",
        "    # Check if embeddings already exist\n",
        "    cache_file = f\"embeddings_{model_name.replace('/', '_')}.pkl\"\n",
        "\n",
        "    if os.path.exists(cache_file) and use_cached:\n",
        "        print(f\"Loading cached embeddings from {cache_file}\")\n",
        "        with open(cache_file, 'rb') as f:\n",
        "            data = pickle.load(f)\n",
        "            # Check if it's the new format or old format\n",
        "            if isinstance(data, tuple) and len(data) == 2:\n",
        "                embeddings, model = data\n",
        "            else:\n",
        "                # Old format - just embeddings\n",
        "                embeddings = data\n",
        "                from sentence_transformers import SentenceTransformer\n",
        "                model = SentenceTransformer(model_name)\n",
        "            return embeddings, model\n",
        "\n",
        "    print(f\"Creating embeddings using {model_name}...\")\n",
        "\n",
        "    # Load model\n",
        "    from sentence_transformers import SentenceTransformer\n",
        "    model = SentenceTransformer(model_name)\n",
        "\n",
        "    # Generate embeddings\n",
        "    embeddings = {}\n",
        "    for term in tqdm(terms):\n",
        "        embeddings[term] = model.encode(term)\n",
        "\n",
        "    # Save embeddings for future use\n",
        "    with open(cache_file, 'wb') as f:\n",
        "        pickle.dump((embeddings, model), f)\n",
        "\n",
        "    print(f\"Created embeddings for {len(embeddings)} standard terms.\")\n",
        "    return embeddings, model\n",
        "\n",
        "def visualize_embeddings(embeddings):\n",
        "    \"\"\"Visualize term embeddings in 2D using UMAP\"\"\"\n",
        "    # Extract embeddings and terms\n",
        "    terms = list(embeddings.keys())\n",
        "    embedding_matrix = np.array([embeddings[term] for term in terms])\n",
        "\n",
        "    # Reduce dimensionality for visualization\n",
        "    reducer = umap.UMAP(n_neighbors=5, min_dist=0.3, metric='cosine')\n",
        "    embedding_2d = reducer.fit_transform(embedding_matrix)\n",
        "\n",
        "    # Create a dataframe for plotting\n",
        "    vis_df = pd.DataFrame({\n",
        "        'term': terms,\n",
        "        'x': embedding_2d[:, 0],\n",
        "        'y': embedding_2d[:, 1],\n",
        "        'word_count': [len(term.split()) for term in terms]\n",
        "    })\n",
        "\n",
        "    # Plot\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    sns.scatterplot(data=vis_df, x='x', y='y', hue='word_count', size='word_count',\n",
        "                    sizes=(20, 200), alpha=0.7, palette='viridis')\n",
        "\n",
        "    # Add labels for points - but be selective to avoid overcrowding\n",
        "    for idx, row in vis_df.sample(min(20, len(vis_df))).iterrows():\n",
        "        plt.text(row['x']+0.1, row['y']+0.1, row['term'], fontsize=8)\n",
        "\n",
        "    plt.title('Visualization of Standard Anatomical Term Embeddings')\n",
        "    plt.savefig('standard_terms_embedding_visualization.png')\n",
        "    plt.show()\n",
        "    print(\"Saved visualization as 'standard_terms_embedding_visualization.png'\")\n",
        "\n",
        "    return vis_df\n",
        "\n",
        "def load_or_create_standard_embeddings(input_df=None):\n",
        "    \"\"\"Load standard term embeddings from cache or create new ones\"\"\"\n",
        "    if os.path.exists(STD_TERMS_CACHE):\n",
        "        print(f\"Loading standard terms from cache: {STD_TERMS_CACHE}\")\n",
        "        with open(STD_TERMS_CACHE, 'rb') as f:\n",
        "            saved = pickle.load(f)\n",
        "        standard_terms = saved[\"standard_terms\"]\n",
        "        standard_embeddings = saved[\"embeddings\"]\n",
        "        model = saved[\"model\"]\n",
        "        print(f\"Loaded {len(standard_terms)} standard FaceBase terms.\")\n",
        "        return standard_terms, standard_embeddings, model\n",
        "\n",
        "    # If no cached data, create new embeddings\n",
        "    if input_df is None:\n",
        "        input_df = upload_input_dataset()\n",
        "\n",
        "    standard_terms = extract_standard_terms(input_df)\n",
        "    print(f\"\\nExtracted {len(standard_terms)} standard terms:\")\n",
        "    for i, term in enumerate(standard_terms, 1):\n",
        "        print(f\"{i}. {term}\")\n",
        "\n",
        "    # Create embeddings for standard terms\n",
        "    standard_embeddings, model = create_embeddings(standard_terms)\n",
        "\n",
        "    # Visualize embeddings\n",
        "    vis_df = visualize_embeddings(standard_embeddings)\n",
        "\n",
        "    # Save standard terms and their embeddings\n",
        "    output = {\n",
        "        'standard_terms': standard_terms,\n",
        "        'embeddings': standard_embeddings,\n",
        "        'model': model\n",
        "    }\n",
        "\n",
        "    with open(STD_TERMS_CACHE, 'wb') as f:\n",
        "        pickle.dump(output, f)\n",
        "\n",
        "    print(f\"\\nEmbedded all standard terms and saved to '{STD_TERMS_CACHE}'\")\n",
        "    return standard_terms, standard_embeddings, model\n",
        "\n",
        "def compute_top_n_matches(df, model, standard_terms, standard_embeddings, unc_col=\"anatomy_uncurated\", top_n=3):\n",
        "    \"\"\"Compute top N most similar standard terms for each uncurated term\"\"\"\n",
        "\n",
        "    def get_top_matches(term, n=top_n):\n",
        "        emb = model.encode(term)\n",
        "        sims = [(t, cosine_similarity([emb], [standard_embeddings[t]])[0][0])\n",
        "                for t in standard_terms]\n",
        "        sims.sort(key=lambda x: x[1], reverse=True)\n",
        "        return sims[:n]\n",
        "\n",
        "    # Add result columns\n",
        "    for i in range(1, top_n+1):\n",
        "        df[f\"match_{i}\"] = None\n",
        "        df[f\"score_{i}\"] = None\n",
        "\n",
        "    # Compute top matches for each row\n",
        "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
        "        term = row[unc_col]\n",
        "        if pd.isna(term): continue\n",
        "        matches = get_top_matches(term)\n",
        "\n",
        "        # Print just a single example for the first few terms\n",
        "        if idx < 5:\n",
        "            print(f\"Sample - Uncurated term: {term}\")\n",
        "            print(f\"  Top match: {matches[0][0]} (similarity score: {matches[0][1]:.4f})\")\n",
        "\n",
        "        for i, (m, s) in enumerate(matches, 1):\n",
        "            df.loc[idx, f\"match_{i}\"] = m\n",
        "            df.loc[idx, f\"score_{i}\"] = s\n",
        "\n",
        "    print(f\"Computed top {top_n} matches for {len(df)} terms.\")\n",
        "    return df\n",
        "\n",
        "# ================ LLM FUNCTIONALITY ===================\n",
        "# System prompts\n",
        "SYSTEM_PROMPT_STD_TERMS = \"\"\"You are an expert biomedical curator.\n",
        "\n",
        "Below is the entire FaceBase canonical anatomy vocabulary:\n",
        "\n",
        "{vocab_block}\n",
        "\n",
        "For each uncurated phrase you receive, return:\n",
        "  \u2192 curated_term  = the SINGLE most appropriate canonical term\n",
        "                    from the list above, OR \"UNKNOWN\"\n",
        "  \u2192 confidence    = 0\u20111 (1.0 = absolutely sure)\n",
        "\n",
        "Respond **only** with a JSON list (same order).\"\"\"\n",
        "\n",
        "SYSTEM_PROMPT_SIMILARITY = \"\"\"You are an expert biomedical curator.\n",
        "\n",
        "For each record you receive:\n",
        "- an uncurated anatomy phrase\n",
        "- biological context (species, stage, description)\n",
        "- the three highest\u2011similarity candidates from the full FaceBase vocabulary\n",
        "\n",
        "Your task is to *curate* the uncurated phrase\u2014produce the single best\n",
        "canonical FaceBase term you would assign as an expert curator. You may\n",
        "choose one of the three candidates *or* write a different canonical term\n",
        "if none is satisfactory. If no suitable FaceBase term exists, return\n",
        "\"UNKNOWN\". Always include a confidence score (0\u20111).\n",
        "\n",
        "Return only a JSON list (same order) where each object has:\n",
        "  \"curated_term\": <string>\n",
        "  \"confidence\":   <float 0\u20111>\n",
        "\"\"\"\n",
        "\n",
        "JSON_REMINDER = \"Return ONLY the raw JSON list\u2014no markdown, no commentary.\"\n",
        "\n",
        "def llm_curate_batch(batch, system_prompt, is_similarity_guided=False, standard_terms=None, unc_col=\"anatomy_uncurated\"):\n",
        "    \"\"\"Generic LLM curation function that supports different prompt styles\"\"\"\n",
        "\n",
        "    if is_similarity_guided:\n",
        "        # Context-enriched similarity-guided approach (with top matches)\n",
        "        user_lines = []\n",
        "        for i, r in enumerate(batch):\n",
        "            ctx = format_context(r, CONTEXT_COLS, CONTEXT_CHARS)\n",
        "\n",
        "            # Candidate list lines\n",
        "            cand_lines = []\n",
        "            for label, j in zip(\"ABC\", [1, 2, 3]):\n",
        "                m, s = r[f\"match_{j}\"], r[f\"score_{j}\"]\n",
        "                sim = f\"(sim={s:.3f})\" if SHOW_SCORES else \"\"\n",
        "                cand_lines.append(f\"{label}) {m} {sim}\".strip())\n",
        "\n",
        "            line_prefix = \"curate among\"\n",
        "\n",
        "            user_lines.append(\n",
        "                f\"{i}. uncurated: {r[unc_col]}\\n\"\n",
        "                f\"   context: {ctx}\\n\"\n",
        "                f\"   {line_prefix}:\\n     \" + \"\\n     \".join(cand_lines)\n",
        "            )\n",
        "    else:\n",
        "        # Context-enriched Standard terms guided approach\n",
        "        if standard_terms is None:\n",
        "            raise ValueError(\"Standard terms must be provided for standard terms guided curation\")\n",
        "\n",
        "        # Format the vocabulary block\n",
        "        vocab_block = \"\\n\".join(f\"- {t}\" for t in standard_terms)\n",
        "        system_prompt = system_prompt.format(vocab_block=vocab_block)\n",
        "\n",
        "        user_lines = []\n",
        "        for i, r in enumerate(batch):\n",
        "            ctx = format_context(r, CONTEXT_COLS, CONTEXT_CHARS)\n",
        "            user_lines.append(f\"{i}. term: {r[unc_col]}\\n   context: {ctx}\")\n",
        "\n",
        "    # DEBUG: Print the prompt for the first term\n",
        "    if not hasattr(llm_curate_batch, 'approach_seen'):\n",
        "        llm_curate_batch.approach_seen = set()\n",
        "\n",
        "    approach_type = \"similarity-guided\" if is_similarity_guided else \"standard-terms-guided\"\n",
        "    if approach_type not in llm_curate_batch.approach_seen:\n",
        "        print(f\"\\n{'='*50}\")\n",
        "        print(f\"PROMPT FOR FIRST TERM USING {approach_type.upper()} APPROACH\")\n",
        "        print(f\"{'='*50}\")\n",
        "        print(\"SYSTEM PROMPT:\")\n",
        "        print(system_prompt[:1000] + (\"...\" if len(system_prompt) > 1000 else \"\"))\n",
        "        print(\"\\nUSER PROMPT (first term only):\")\n",
        "        if user_lines:\n",
        "            print(user_lines[0])\n",
        "        print(f\"{'='*50}\\n\")\n",
        "        llm_curate_batch.approach_seen.add(approach_type)\n",
        "\n",
        "    # Call the OpenAI API\n",
        "    resp = openai.ChatCompletion.create(\n",
        "        model=MODEL_NAME,\n",
        "        temperature=TEMPERATURE,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": \"\\n\\n\".join(user_lines)},\n",
        "            {\"role\": \"user\", \"content\": JSON_REMINDER}\n",
        "        ]\n",
        "    )\n",
        "    response_text = resp.choices[0].message.content.strip()\n",
        "\n",
        "    # Parse the JSON response\n",
        "    return robust_json_parse(response_text)\n",
        "\n",
        "# Initialize the static set to track which approaches we've seen\n",
        "llm_curate_batch.approach_seen = set()\n",
        "\n",
        "def llm_curate_dataset(df, approach_type, standard_terms=None):\n",
        "    \"\"\"Curate dataset using the specified approach and configuration\"\"\"\n",
        "    records = df.to_dict(\"records\")\n",
        "    unc_col = \"anatomy_uncurated\"\n",
        "\n",
        "    # Configure approach\n",
        "    if approach_type == \"standard_terms\":\n",
        "        if standard_terms is None:\n",
        "            raise ValueError(\"Standard terms must be provided for standard terms guided curation\")\n",
        "\n",
        "        system_prompt = SYSTEM_PROMPT_STD_TERMS\n",
        "        is_similarity_guided = False\n",
        "        suffix = \"std_terms\"\n",
        "\n",
        "    elif approach_type == \"similarity\":\n",
        "        system_prompt = SYSTEM_PROMPT_SIMILARITY\n",
        "        is_similarity_guided = True\n",
        "        suffix = \"similarity\"\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown approach type: {approach_type}\")\n",
        "\n",
        "    # Process the dataset in batches\n",
        "    def process_batch(batch):\n",
        "        return llm_curate_batch(\n",
        "            batch,\n",
        "            system_prompt=system_prompt,\n",
        "            is_similarity_guided=is_similarity_guided,\n",
        "            standard_terms=standard_terms\n",
        "        )\n",
        "\n",
        "    results = process_in_batches(records, BATCH_SIZE, process_batch)\n",
        "\n",
        "    # Extract results - Ensuring results match dataframe length\n",
        "    curated_terms = []\n",
        "    confidences = []\n",
        "\n",
        "    for i, record in enumerate(records):\n",
        "        if i < len(results):\n",
        "            result = results[i]\n",
        "            curated_terms.append(result.get(\"curated_term\", \"UNKNOWN\"))\n",
        "            confidences.append(float(result.get(\"confidence\", 0)))\n",
        "        else:\n",
        "            # Handle any missing results\n",
        "            print(f\"Warning: Missing result for record {i}, using default values\")\n",
        "            curated_terms.append(\"UNKNOWN\")\n",
        "            confidences.append(0.0)\n",
        "\n",
        "    # Add to dataframe\n",
        "    df[f\"curated_term_{suffix}\"] = curated_terms\n",
        "    df[f\"confidence_{suffix}\"] = confidences\n",
        "    df[f\"confident_{suffix}\"] = df[f\"confidence_{suffix}\"] >= CONF_THRESHOLD\n",
        "\n",
        "    # Save results\n",
        "    output_file = f\"curated_{suffix}.csv\"\n",
        "    df.to_csv(output_file, index=False)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy, confident_count, total_count = calculate_accuracy(df, suffix)\n",
        "    print(f\"\u2705 Saved \u2192 {output_file} (\u2265{CONF_THRESHOLD}: {confident_count}/{total_count}, {accuracy:.2%})\")\n",
        "\n",
        "    # Download the file\n",
        "    files.download(output_file)\n",
        "\n",
        "    return df\n",
        "\n",
        "def hybrid_curation_strategy(df, standard_terms, standard_embeddings, model, strategy=\"similarity_first\"):\n",
        "    \"\"\"Two-stage hybrid curation strategy with configurable order\"\"\"\n",
        "\n",
        "    if strategy == \"similarity_first\":\n",
        "        # First stage: Curate all terms with similarity-guided approach\n",
        "        print(\"\\n==== STAGE 1: CONTEXT-ENRICHED SIMILARITY-GUIDED CURATION ====\")\n",
        "        df_first_stage = llm_curate_dataset(\n",
        "            df.copy(),\n",
        "            approach_type=\"similarity\",\n",
        "            standard_terms=standard_terms\n",
        "        )\n",
        "\n",
        "        # Identify low confidence terms\n",
        "        low_conf_mask = df_first_stage[\"confidence_similarity\"] < CONF_THRESHOLD\n",
        "        low_conf_count = low_conf_mask.sum()\n",
        "\n",
        "        stage1_suffix = \"similarity\"\n",
        "        stage2_suffix = \"std_terms\"\n",
        "        second_stage_name = \"CONTEXT-ENRICHED STANDARD TERMS GUIDED\"\n",
        "\n",
        "    elif strategy == \"standard_terms_first\":\n",
        "        # First stage: Curate all terms with standard terms approach\n",
        "        print(\"\\n==== STAGE 1: CONTEXT-ENRICHED STANDARD TERMS GUIDED CURATION ====\")\n",
        "        df_first_stage = llm_curate_dataset(\n",
        "            df.copy(),\n",
        "            approach_type=\"standard_terms\",\n",
        "            standard_terms=standard_terms\n",
        "        )\n",
        "\n",
        "        # Identify low confidence terms\n",
        "        low_conf_mask = df_first_stage[\"confidence_std_terms\"] < CONF_THRESHOLD\n",
        "        low_conf_count = low_conf_mask.sum()\n",
        "\n",
        "        stage1_suffix = \"std_terms\"\n",
        "        stage2_suffix = \"similarity\"\n",
        "        second_stage_name = \"CONTEXT-ENRICHED SIMILARITY-GUIDED\"\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown strategy: {strategy}\")\n",
        "\n",
        "    # Report first stage results\n",
        "    print(f\"\\nStage 1 results: {len(df_first_stage) - low_conf_count}/{len(df_first_stage)} terms curated with high confidence\")\n",
        "    print(f\"Moving {low_conf_count} low-confidence terms to stage 2...\")\n",
        "\n",
        "    # Debug: Print a sample of low confidence terms\n",
        "    if low_conf_count > 0:\n",
        "        low_conf_df = df_first_stage[low_conf_mask]\n",
        "        sample_count = min(5, len(low_conf_df))\n",
        "        print(f\"\\nSample of low confidence terms being sent to stage 2 ({sample_count} of {low_conf_count}):\")\n",
        "        for i, (_, row) in enumerate(low_conf_df.head(sample_count).iterrows()):\n",
        "            print(f\"Term: {row['anatomy_uncurated']}\")\n",
        "            print(f\"  \u2192 First stage mapping: {row[f'curated_term_{stage1_suffix}']} (confidence: {row[f'confidence_{stage1_suffix}']:.2f})\")\n",
        "            if i < sample_count - 1:  # Don't print separator after last item\n",
        "                print()\n",
        "\n",
        "    if low_conf_count == 0:\n",
        "        print(\"No low-confidence terms to process in stage 2.\")\n",
        "        # Just rename the columns to match the hybrid naming\n",
        "        strategy_suffix = \"hybrid\"\n",
        "        df_final = df_first_stage.rename(columns={\n",
        "            f\"curated_term_{stage1_suffix}\": f\"curated_term_{strategy_suffix}\",\n",
        "            f\"confidence_{stage1_suffix}\": f\"confidence_{strategy_suffix}\",\n",
        "            f\"confident_{stage1_suffix}\": f\"confident_{strategy_suffix}\"\n",
        "        })\n",
        "\n",
        "        # Calculate accuracy\n",
        "        accuracy, confident_count, total_count = calculate_accuracy(df_final, strategy_suffix)\n",
        "\n",
        "        # Save results\n",
        "        output_file = f\"curated_{strategy_suffix}.csv\"\n",
        "        df_final.to_csv(output_file, index=False)\n",
        "        print(f\"\u2705 Saved \u2192 {output_file} (\u2265{CONF_THRESHOLD}: {confident_count}/{total_count}, {accuracy:.2%})\")\n",
        "        files.download(output_file)\n",
        "\n",
        "        return df_final\n",
        "\n",
        "    # Extract only the low confidence rows for stage 2\n",
        "    df_low_conf = df_first_stage[low_conf_mask].copy()\n",
        "\n",
        "    # Second stage with opposite approach\n",
        "    print(f\"\\n==== STAGE 2: {second_stage_name} CURATION (FOR LOW CONFIDENCE TERMS) ====\")\n",
        "\n",
        "    second_approach = \"similarity\" if stage2_suffix == \"similarity\" else \"standard_terms\"\n",
        "    df_second_stage = llm_curate_dataset(\n",
        "        df_low_conf,\n",
        "        approach_type=second_approach,\n",
        "        standard_terms=standard_terms\n",
        "    )\n",
        "\n",
        "    # Merge results: use second stage results for previously low-confidence terms\n",
        "    df_final = df_first_stage.copy()\n",
        "    df_final.loc[low_conf_mask, f\"curated_term_{stage1_suffix}\"] = df_second_stage[f\"curated_term_{stage2_suffix}\"]\n",
        "    df_final.loc[low_conf_mask, f\"confidence_{stage1_suffix}\"] = df_second_stage[f\"confidence_{stage2_suffix}\"]\n",
        "    df_final.loc[low_conf_mask, f\"confident_{stage1_suffix}\"] = df_second_stage[f\"confident_{stage2_suffix}\"]\n",
        "\n",
        "    # Rename columns to reflect hybrid strategy\n",
        "    strategy_suffix = \"hybrid\"\n",
        "    df_final = df_final.rename(columns={\n",
        "        f\"curated_term_{stage1_suffix}\": f\"curated_term_{strategy_suffix}\",\n",
        "        f\"confidence_{stage1_suffix}\": f\"confidence_{strategy_suffix}\",\n",
        "        f\"confident_{stage1_suffix}\": f\"confident_{strategy_suffix}\"\n",
        "    })\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy, confident_count, total_count = calculate_accuracy(df_final, strategy_suffix)\n",
        "\n",
        "    # Save results\n",
        "    output_file = f\"curated_{strategy_suffix}.csv\"\n",
        "    df_final.to_csv(output_file, index=False)\n",
        "    print(f\"\u2705 Saved \u2192 {output_file} (\u2265{CONF_THRESHOLD}: {confident_count}/{total_count}, {accuracy:.2%})\")\n",
        "    files.download(output_file)\n",
        "\n",
        "    return df_final\n",
        "\n",
        "def compare_approaches(similarity_df=None, std_terms_df=None, sim_std_df=None, std_sim_df=None):\n",
        "    \"\"\"Compare the accuracy of different approaches\"\"\"\n",
        "    results = {}\n",
        "\n",
        "    if similarity_df is not None:\n",
        "        accuracy, confident_count, total_count = calculate_accuracy(similarity_df, \"similarity\")\n",
        "        results[\"Context-enriched similarity-guided Curation\"] = {\"accuracy\": accuracy, \"confident\": confident_count, \"total\": total_count}\n",
        "\n",
        "    if std_terms_df is not None:\n",
        "        accuracy, confident_count, total_count = calculate_accuracy(std_terms_df, \"std_terms\")\n",
        "        results[\"Context-enriched Standard terms guided Curation\"] = {\"accuracy\": accuracy, \"confident\": confident_count, \"total\": total_count}\n",
        "\n",
        "    if sim_std_df is not None:\n",
        "        accuracy, confident_count, total_count = calculate_accuracy(sim_std_df, \"hybrid\")\n",
        "        results[\"Hybrid Context-enriched Curation (Similarity \u2192 Standard)\"] = {\"accuracy\": accuracy, \"confident\": confident_count, \"total\": total_count}\n",
        "\n",
        "    if std_sim_df is not None:\n",
        "        accuracy, confident_count, total_count = calculate_accuracy(std_sim_df, \"hybrid\")\n",
        "        results[\"Hybrid Context-enriched Curation (Standard \u2192 Similarity)\"] = {\"accuracy\": accuracy, \"confident\": confident_count, \"total\": total_count}\n",
        "\n",
        "    # Print comparison table\n",
        "    print(\"\\n===== ACCURACY COMPARISON =====\")\n",
        "    print(f\"Confidence threshold: {CONF_THRESHOLD}\")\n",
        "    print(\"-\" * 90)\n",
        "    print(f\"{'Approach':<55} | {'Accuracy':<10} | {'High Confidence':<15} | {'Total':<5}\")\n",
        "    print(\"-\" * 90)\n",
        "\n",
        "    for approach, data in results.items():\n",
        "        print(f\"{approach:<55} | {data['accuracy']:.2%} | {data['confident']:<15} | {data['total']:<5}\")\n",
        "\n",
        "    print(\"-\" * 90)\n",
        "\n",
        "    return results\n",
        "\n",
        "# ================ MAIN EXECUTION =====================\n",
        "def main():\n",
        "    \"\"\"Main pipeline execution flow with extended options\"\"\"\n",
        "    print(\"========== FACEBASE ANATOMICAL TERM CURATION PIPELINE ==========\")\n",
        "    print(\"1. Single approach: Context-enriched similarity-guided Curation\")\n",
        "    print(\"2. Single approach: Context-enriched Standard terms guided Curation\")\n",
        "    print(\"3. Two-stage: Hybrid Context-enriched Curation (Similarity \u2192 Standard)\")\n",
        "    print(\"4. Two-stage: Hybrid Context-enriched Curation (Standard \u2192 Similarity)\")\n",
        "    print(\"5. Run all approaches and compare results\")\n",
        "    choice = input(\"Enter your choice (1-5): \")\n",
        "\n",
        "    # Load standard embeddings\n",
        "    standard_terms, standard_embeddings, model = load_or_create_standard_embeddings()\n",
        "\n",
        "    # Upload uncurated CSV file\n",
        "    print(\"\\n==== LOADING UNCURATED DATA ====\")\n",
        "    print(\"Upload your uncurated CSV file...\")\n",
        "    uploaded = files.upload()\n",
        "    uncurated_file = next(iter(uploaded))\n",
        "    uncurated_df = pd.read_csv(uncurated_file)\n",
        "\n",
        "    # Compute top matches for embedding-based approaches\n",
        "    matched_df = compute_top_n_matches(\n",
        "        uncurated_df,\n",
        "        model,\n",
        "        standard_terms,\n",
        "        standard_embeddings\n",
        "    )\n",
        "    matched_df.to_csv(\"uncurated_with_matches.csv\", index=False)\n",
        "    print(\"\u2705 Saved \u2192 uncurated_with_matches.csv\")\n",
        "\n",
        "    # Initialize result DataFrames\n",
        "    similarity_df = None\n",
        "    std_terms_df = None\n",
        "    sim_std_df = None\n",
        "    std_sim_df = None\n",
        "\n",
        "    if choice in ('1', '5'):\n",
        "        print(\"\\n==== RUNNING CONTEXT-ENRICHED SIMILARITY-GUIDED CURATION ====\")\n",
        "        similarity_df = llm_curate_dataset(\n",
        "            matched_df.copy(),\n",
        "            approach_type=\"similarity\",\n",
        "            standard_terms=standard_terms\n",
        "        )\n",
        "\n",
        "    if choice in ('2', '5'):\n",
        "        print(\"\\n==== RUNNING CONTEXT-ENRICHED STANDARD TERMS GUIDED CURATION ====\")\n",
        "        std_terms_df = llm_curate_dataset(\n",
        "            matched_df.copy(),\n",
        "            approach_type=\"standard_terms\",\n",
        "            standard_terms=standard_terms\n",
        "        )\n",
        "\n",
        "    if choice in ('3', '5'):\n",
        "        print(\"\\n==== RUNNING HYBRID CONTEXT-ENRICHED CURATION (SIMILARITY \u2192 STANDARD) ====\")\n",
        "        sim_std_df = hybrid_curation_strategy(\n",
        "            matched_df.copy(),\n",
        "            standard_terms=standard_terms,\n",
        "            standard_embeddings=standard_embeddings,\n",
        "            model=model,\n",
        "            strategy=\"similarity_first\"\n",
        "        )\n",
        "\n",
        "    if choice in ('4', '5'):\n",
        "        print(\"\\n==== RUNNING HYBRID CONTEXT-ENRICHED CURATION (STANDARD \u2192 SIMILARITY) ====\")\n",
        "        std_sim_df = hybrid_curation_strategy(\n",
        "            matched_df.copy(),\n",
        "            standard_terms=standard_terms,\n",
        "            standard_embeddings=standard_embeddings,\n",
        "            model=model,\n",
        "            strategy=\"standard_terms_first\"\n",
        "        )\n",
        "\n",
        "    if choice == '5':\n",
        "        # Compare all approaches\n",
        "        compare_approaches(\n",
        "            similarity_df=similarity_df,\n",
        "            std_terms_df=std_terms_df,\n",
        "            sim_std_df=sim_std_df,\n",
        "            std_sim_df=std_sim_df\n",
        "        )\n",
        "\n",
        "    print(\"\\n\u2705 PIPELINE EXECUTION COMPLETE\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e901ca960019424ab2531c68cc1e2ad5",
            "8a18fc9c016144598f6beefc861731e8",
            "fc60c5f2976e47e3962153bea92ca457",
            "9aa2710291164a529e0f5629ab608fa4",
            "e4e41eb5844a48c798606dfbdd8fa2a0",
            "4f933309b0ef4a1e8fa64c1933c07752",
            "84e035aa014742379742f28191084152",
            "9622d56200b64381906eb7bd122c5230",
            "af961882ae154cbfb86d7f1022039ab1",
            "3550fccfcd68458fb12afbc275ba39d8",
            "7b8fa51577ad47fbac35a16fe4ccdfb8",
            "8b9fb19e7c6d4f3e94bf0240f53e54c1",
            "f99220dbcaaf4d43979579046998f62d",
            "d17da2a71b1649c1840ebe60bfa491fc",
            "1420088b938b44d3967db008b508dbc5",
            "fa957aee9e2149df8a8fb1e6a5749dea",
            "aaa884ba5fc24db6b57fae58fdfcd9b9",
            "364f76e00a96468385ac990016f15e85",
            "14d046a32f5c43d2b2d03d749f61a41b",
            "ffaf5d0ddae44746b6bcbd18eb821055",
            "97a0b97408e846f68aee3027b2be3abd",
            "1539bc3363244aeb88ef0b6e60c7d274",
            "089fb458067c4e6a813f66142e11161a",
            "2393e8f8de374c59a5b83cc2afd19292",
            "af45f48d01c34c1d97b9e58205e7f42c",
            "b51a24a57bac41ca845f78a0bd27b567",
            "66955c19400e45dfabc44334bf426e72",
            "c401742c93cb49d58be481549049c3ff",
            "b35864085fd942828eb4395970fc84cb",
            "b868cd1bcf42477c98ac53fde5a7b6be",
            "fcb6608cc42c49f8ba568a4b0c27cd06",
            "f7e8ac9eff624817b35709be9da2a8f2",
            "57b88aec46ed4d12a881d69ac7c30e1a",
            "c7bc45c198cc4ab48ca23bc0a48a885b",
            "53bd4e68a9544e0c92207b2e570d3b1e",
            "8e3dd26e1c46439e97df8865dcfb27c5",
            "cde0e865ba1f4c6b8a04b14643da1c7f",
            "a0ec448e34ab4d4b92a96fd012831712",
            "adfc8034ddfb40a7a4900a68bbadd177",
            "56b84c03517749ebb3b0e635a742ab68",
            "dec24c6b151542ad85d91f6e4bf739d4",
            "cb9fc9e010ec49a2be41439f568816be",
            "49778755790c4b76a55d71cbc97c2f09",
            "1e503ecf8703482fbc0cc825be91c460",
            "64771b3a481c465fa567a1165319779f",
            "467dde7e79d541e285192e0441838d07",
            "f588990190a44b53a8d67b6f1e948f76",
            "820153c62a1641b690e0766ff3ccc321",
            "88ddd0776bc14684ae9687311040da75",
            "c3db08ae191144f3870bd7e6cba9ffa9",
            "d25bb76af21e41e3a37efadba3f549d4",
            "14046dd8cece4ae69072505d4260495b",
            "800c9079e4c4478d83c822171d6370f7",
            "5f597d30646a44eb8bb0489989c58c53",
            "ea6cecc299264801ae392ef37b965067",
            "2fd7cfdd58cc4668abfb2c0d60bd46ee",
            "aa68b2665b674209bbdf01e902f25036",
            "aeed1b4655da425c92e191af69f3bcd0",
            "21c662e4b07349c5a83f0cdd0f48493a",
            "bd1fada78d124c1896ed073e5d785b5f",
            "60d152a9c6794188ad55bd43bcbe972b",
            "ca9365da9af643a5a983ac050acc6025",
            "6e19bd14c84d49b0ae7a1218b1e70dc0",
            "f4a03c2957e3460d99ca44d3e7d468fd",
            "0fec8543f55048f788f4c00acd5155e1",
            "a527c54993e745708a466167e7d20d23",
            "38b7873e36c848aeb2168ffd44951244",
            "6db91ca20fc245c191a705555079bb9f",
            "decf9a0b669b44cc99bc623774044d82",
            "a6edcd75acca4d2a8b6193e1b47afc35",
            "9692d5eecaa74ee18616eb0b4afd842f",
            "4a3692f8680c48dbbd9f05c708563e69",
            "01a5148a2a70461daca24b3377d2293b",
            "737a577cf74e4d208d370294bb80cff6",
            "e2f801ef6ccb463eafc9683d67e12124",
            "122f657efc014aa0b11428d82d76bff6",
            "a9e6c52e990c4f12afcdc93abebd879e"
          ]
        },
        "id": "VzcwXBj8jtnl",
        "outputId": "aee8a288-b2e2-4e8f-c918-16ab2f7f8699"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========== FACEBASE ANATOMICAL TERM CURATION PIPELINE ==========\n",
            "1. Single approach: Context-enriched similarity-guided Curation\n",
            "2. Single approach: Context-enriched Standard terms guided Curation\n",
            "3. Two-stage: Hybrid Context-enriched Curation (Similarity \u2192 Standard)\n",
            "4. Two-stage: Hybrid Context-enriched Curation (Standard \u2192 Similarity)\n",
            "5. Run all approaches and compare results\n",
            "Enter your choice (1-5): 5\n",
            "Loading standard terms from cache: standard_terms_embeddings.pkl\n",
            "Loaded 50 standard FaceBase terms.\n",
            "\n",
            "==== LOADING UNCURATED DATA ====\n",
            "Upload your uncurated CSV file...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b874fd7b-1cd7-4a06-b5b5-b606d9b02274\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b874fd7b-1cd7-4a06-b5b5-b606d9b02274\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving uncurated_highquality_100_rows_final.csv to uncurated_highquality_100_rows_final (3).csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e901ca960019424ab2531c68cc1e2ad5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample - Uncurated term: median palatal junction\n",
            "  Top match: palate (similarity score: 0.6935)\n",
            "Sample - Uncurated term: median palatal junction\n",
            "  Top match: palate (similarity score: 0.6935)\n",
            "Sample - Uncurated term: the maxillary palatine suture of the developing specimen\n",
            "  Top match: maxillary palatine suture (similarity score: 0.8516)\n",
            "Sample - Uncurated term: maxillary palatine suture, fibrous connective tissue region\n",
            "  Top match: maxillary palatine suture (similarity score: 0.8328)\n",
            "Sample - Uncurated term: lambdoid cranial joint\n",
            "  Top match: lambdoid suture (similarity score: 0.8319)\n",
            "Computed top 3 matches for 100 terms.\n",
            "\u2705 Saved \u2192 uncurated_with_matches.csv\n",
            "\n",
            "==== RUNNING CONTEXT-ENRICHED SIMILARITY-GUIDED CURATION ====\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/25 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8b9fb19e7c6d4f3e94bf0240f53e54c1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "PROMPT FOR FIRST TERM USING SIMILARITY-GUIDED APPROACH\n",
            "==================================================\n",
            "SYSTEM PROMPT:\n",
            "You are an expert biomedical curator.\n",
            "\n",
            "For each record you receive:\n",
            "- an uncurated anatomy phrase\n",
            "- biological context (species, stage, description)\n",
            "- the three highest\u2011similarity candidates from the full FaceBase vocabulary\n",
            "\n",
            "Your task is to *curate* the uncurated phrase\u2014produce the single best\n",
            "canonical FaceBase term you would assign as an expert curator. You may\n",
            "choose one of the three candidates *or* write a different canonical term\n",
            "if none is satisfactory. If no suitable FaceBase term exists, return\n",
            "\"UNKNOWN\". Always include a confidence score (0\u20111).\n",
            "\n",
            "Return only a JSON list (same order) where each object has:\n",
            "  \"curated_term\": <string>\n",
            "  \"confidence\":   <float 0\u20111>\n",
            "\n",
            "\n",
            "USER PROMPT (first term only):\n",
            "0. uncurated: median palatal junction\n",
            "   context: species: Mus musculus | stage_description: Mouse embryonic stage E16.5 | dataset_description: \t\n",
            "RNA-Seq libraries are from laser capture microdissections of C57BL/6J Fgfr2+/+ (W) and C57BL/6J Apert syndrome EIIA-Cre+;Fgfr2+/S252W (A) mice, at development stages TS24/E16.5 (6) and TS26/E18.5 (8), from the interpalatine suture (IP), with 5 biological replicates (1-5), of the suture mesenchyme (SM) and interpalatine bone osteogenic front (PL). \u201cW8IP1SM\u201d, for example, indicates WT, E18.5, interpalatine suture, replicate 1, suture mesenchyme.\n",
            "   curate among:\n",
            "     A) palate (sim=0.693)\n",
            "     B) Medial-nasal process (sim=0.658)\n",
            "     C) Lateral-nasal process (sim=0.640)\n",
            "==================================================\n",
            "\n",
            "\u2705 Saved \u2192 curated_similarity.csv (\u22650.8: 91/100, 91.00%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f16e33aa-050d-4ed0-9e6a-aa263a6e750d\", \"curated_similarity.csv\", 92661)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==== RUNNING CONTEXT-ENRICHED STANDARD TERMS GUIDED CURATION ====\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/25 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "089fb458067c4e6a813f66142e11161a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "PROMPT FOR FIRST TERM USING STANDARD-TERMS-GUIDED APPROACH\n",
            "==================================================\n",
            "SYSTEM PROMPT:\n",
            "You are an expert biomedical curator.\n",
            "\n",
            "Below is the entire FaceBase canonical anatomy vocabulary:\n",
            "\n",
            "- interpalatine suture\n",
            "- maxillary palatine suture\n",
            "- lambdoid suture\n",
            "- maxilla\n",
            "- 1st arch mandibular component\n",
            "- mandible\n",
            "- Molar root\n",
            "- secondary palate\n",
            "- coronal suture\n",
            "- root of molar tooth\n",
            "- incisor tooth\n",
            "- interfrontal bone\n",
            "- lower jaw incisor\n",
            "- pharyngeal arch 4\n",
            "- soft palate\n",
            "- buccal vestibule\n",
            "- tooth bud\n",
            "- frontal suture\n",
            "- intermaxillary suture\n",
            "- Inter-premaxillary suture\n",
            "- Medial-nasal process\n",
            "- Maxillary process\n",
            "- Lateral-nasal process\n",
            "- Mandibular process\n",
            "- internasal suture\n",
            "- hard palate\n",
            "- palate\n",
            "- secondary palatal shelf epithelium\n",
            "- dental organ\n",
            "- molar tooth\n",
            "- molar tooth 1\n",
            "- lower jaw molar\n",
            "- upper jaw molar\n",
            "- Cranial vault\n",
            "- Nasal placode\n",
            "- Frontal bone\n",
            "- body of mandible\n",
            "- upper molar 1\n",
            "- sagittal suture\n",
            "- Ectoderm of mandibular part of first pharyngeal arch\n",
            "- mesenchyme of fronto-nasal process\n",
            "- Ectoderm of maxillary process\n",
            "- TS17 ectoderm of frontonasal process\n",
            "- Mese...\n",
            "\n",
            "USER PROMPT (first term only):\n",
            "0. term: median palatal junction\n",
            "   context: species: Mus musculus | stage_description: Mouse embryonic stage E16.5 | dataset_description: \t\n",
            "RNA-Seq libraries are from laser capture microdissections of C57BL/6J Fgfr2+/+ (W) and C57BL/6J Apert syndrome EIIA-Cre+;Fgfr2+/S252W (A) mice, at development stages TS24/E16.5 (6) and TS26/E18.5 (8), from the interpalatine suture (IP), with 5 biological replicates (1-5), of the suture mesenchyme (SM) and interpalatine bone osteogenic front (PL). \u201cW8IP1SM\u201d, for example, indicates WT, E18.5, interpalatine suture, replicate 1, suture mesenchyme.\n",
            "==================================================\n",
            "\n",
            "\u2705 Saved \u2192 curated_std_terms.csv (\u22650.8: 86/100, 86.00%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_55e3f669-d1e8-4cc6-877c-ad2a236b41df\", \"curated_std_terms.csv\", 92567)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==== RUNNING HYBRID CONTEXT-ENRICHED CURATION (SIMILARITY \u2192 STANDARD) ====\n",
            "\n",
            "==== STAGE 1: CONTEXT-ENRICHED SIMILARITY-GUIDED CURATION ====\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/25 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c7bc45c198cc4ab48ca23bc0a48a885b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u2705 Saved \u2192 curated_similarity.csv (\u22650.8: 90/100, 90.00%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7303ca60-d44d-4ee7-86dd-b40267e3a2e7\", \"curated_similarity.csv\", 92667)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Stage 1 results: 90/100 terms curated with high confidence\n",
            "Moving 10 low-confidence terms to stage 2...\n",
            "\n",
            "Sample of low confidence terms being sent to stage 2 (5 of 10):\n",
            "Term: front tooth tooth\n",
            "  \u2192 First stage mapping: UNKNOWN (confidence: 0.00)\n",
            "\n",
            "Term: the interfrontal bone of the developing specimen\n",
            "  \u2192 First stage mapping: interfrontal bone (confidence: 0.75)\n",
            "\n",
            "Term: the buccal vestibule of the developing specimen\n",
            "  \u2192 First stage mapping: buccal vestibule (confidence: 0.77)\n",
            "\n",
            "Term: odontogenic structure primordium\n",
            "  \u2192 First stage mapping: tooth bud (confidence: 0.76)\n",
            "\n",
            "Term: anterior cranial cranial seam\n",
            "  \u2192 First stage mapping: Cranial vault (confidence: 0.79)\n",
            "\n",
            "==== STAGE 2: CONTEXT-ENRICHED STANDARD TERMS GUIDED CURATION (FOR LOW CONFIDENCE TERMS) ====\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "64771b3a481c465fa567a1165319779f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u2705 Saved \u2192 curated_std_terms.csv (\u22650.8: 7/10, 70.00%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_29529e85-b974-4dd9-874d-bdcb6b52190f\", \"curated_std_terms.csv\", 10935)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u2705 Saved \u2192 curated_hybrid.csv (\u22650.8: 97/100, 97.00%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c632c210-022c-47e8-820e-f4af5a32ae2e\", \"curated_hybrid.csv\", 92632)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==== RUNNING HYBRID CONTEXT-ENRICHED CURATION (STANDARD \u2192 SIMILARITY) ====\n",
            "\n",
            "==== STAGE 1: CONTEXT-ENRICHED STANDARD TERMS GUIDED CURATION ====\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/25 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2fd7cfdd58cc4668abfb2c0d60bd46ee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u2705 Saved \u2192 curated_std_terms.csv (\u22650.8: 85/100, 85.00%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e0d2aa5d-c156-4257-a239-212524d85311\", \"curated_std_terms.csv\", 92562)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Stage 1 results: 85/100 terms curated with high confidence\n",
            "Moving 15 low-confidence terms to stage 2...\n",
            "\n",
            "Sample of low confidence terms being sent to stage 2 (5 of 15):\n",
            "Term: premaxilla-maxilla complex\n",
            "  \u2192 First stage mapping: UNKNOWN (confidence: 0.00)\n",
            "\n",
            "Term: premaxilla-maxilla complex\n",
            "  \u2192 First stage mapping: UNKNOWN (confidence: 0.00)\n",
            "\n",
            "Term: craniofacial skeletal element\n",
            "  \u2192 First stage mapping: UNKNOWN (confidence: 0.00)\n",
            "\n",
            "Term: coronal arthrosis\n",
            "  \u2192 First stage mapping: UNKNOWN (confidence: 0.50)\n",
            "\n",
            "Term: front tooth tooth\n",
            "  \u2192 First stage mapping: UNKNOWN (confidence: 0.50)\n",
            "\n",
            "==== STAGE 2: CONTEXT-ENRICHED SIMILARITY-GUIDED CURATION (FOR LOW CONFIDENCE TERMS) ====\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "38b7873e36c848aeb2168ffd44951244"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u2705 Saved \u2192 curated_similarity.csv (\u22650.8: 14/15, 93.33%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2a7b447c-1a46-40ba-b97d-c4ceb94ac780\", \"curated_similarity.csv\", 15299)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u2705 Saved \u2192 curated_hybrid.csv (\u22650.8: 99/100, 99.00%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d638ed22-40b9-44d8-a5f3-26fbe49a7d95\", \"curated_hybrid.csv\", 92642)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== ACCURACY COMPARISON =====\n",
            "Confidence threshold: 0.8\n",
            "------------------------------------------------------------------------------------------\n",
            "Approach                                                | Accuracy   | High Confidence | Total\n",
            "------------------------------------------------------------------------------------------\n",
            "Context-enriched similarity-guided Curation             | 91.00% | 91              | 100  \n",
            "Context-enriched Standard terms guided Curation         | 86.00% | 86              | 100  \n",
            "Hybrid Context-enriched Curation (Similarity \u2192 Standard) | 97.00% | 97              | 100  \n",
            "Hybrid Context-enriched Curation (Standard \u2192 Similarity) | 99.00% | 99              | 100  \n",
            "------------------------------------------------------------------------------------------\n",
            "\n",
            "\u2705 PIPELINE EXECUTION COMPLETE\n"
          ]
        }
      ]
    }
  ]
}